#!/usr/bin/python

import argparse
import json
import subprocess
import sys

############
# psplay_server is the "server" component of psplay - it runs periodically
# from cron, and iterates over all registered splaykeys.
#
# For each splaykey:
#   gets a list of servers that are part of the fleet for a service, and
#   if that has changed:
#   1) If a host has been replaced but the number of servers in the fleet stays
#	the same, give the replacement host the splaykey that its
#	predecessor had. This avoids the need to shift times around.
#   2) If a host has been removed or added, renumber everybody! We change host
#	attributes immediately (could stage it, but that'd make this script
#	more complex and with little benefit - revisit this decision if needed)
#
# Data it works with:
#   machine tagging database - reads and writes, accessible instantly from any
#	host. Let's not depend on any particular one.
#   cache from last mdb read/write

def main():
	cfg = handle_args()
	get_lockfile(cfg.lockfile)
	for skey in get_skey_list():
		# Rebalance global skeys
		hosts    = get_hosts_for_skey_mtag(skey)
		oldhosts = get_hosts_for_skey_cache(skey, cfg.cachefile)
		if hosts_same(hosts, oldhosts):
			continue
		elif num_hosts_same(hosts, oldhosts):
			cache = skey_getcache(cfg.cachefile)
			successors_keyswap(skey, cache, hosts, oldhosts) # updates cache obj and mtags
			cache_store(cache, cfg.cachefile)
		else:
			cache = skey_getcache(cfg.cachefile)
			rekey_all_hosts(skey, hosts, cache) # updates cache obj
			cache_store(cache, cfg.cachefile)
	release_lockfile()

def handle_args():
	optmsgs = {
	"cachefile" : "JSON storage for local cache",
	"lockfile" : "Lockfile",
	}
	parser = argparse.ArgumentParser()
	parser.add_argument('--lockfile', help=optmsgs['lockfile'],
		default='/var/lock/psplay')
	parser.add_argument('--cachefile', help=optmsgs['cachefile'],
		default='/var/run/psplay.json')
	return parser.parse_args()

#####################
# skeylist operations
#
# not sure how I want this to work

def get_skey_list():
	pass

#####################
# Hostlist operations

def hosts_same(first, second):
	# Bool: True if two hostlists are the same
	# It changes list order, but that is ok
	first.sort()
	bar.sort()
	return foo == bar

def num_hosts_same(first, second):
	# Bool: True if two hostlists have same number of elements
	return len(first) == len(second)

#####################
# mtag operations

def get_hosts_for_skey_mtag(skey):
	""" RO """
	pass

def successors_keyswap(skey, cache, hosts, oldhosts):
	""" RW, rewrite cache object and mtag-sync the changes
	The purpose of this is, for every host in hosts that doesn't exist
        in oldhosts, designate it as the unique successor of a host in oldhosts
	that isn't in newhosts, giving it the same offset as what it replaces.
	We rewrite the cache object and update mtags as we go """
	pass

def rekey_all_hosts(skey, hosts, cache):
	""" RW, rewrite cache object and mtag-sync as we go.
	This is used when we need to re-offset everything. """
	pass

#####################
# cache operations
#
# The cache is a json file with the following structure
# key => [host => offset_percent]
# hash stored inside

def skey_getcache(cachejson):
	with open(cachejson) as json_d:
		cache = json.load(json_d)
		json_d.close()
	return cache

def get_hosts_for_skey_cache(skey, cachejson):
	""" RO """
	cache = skey_getcache(cachejson)
	return cache[skey].keys()

def cache_store(cacheobj, cachejson):
	""" W """
	with open(cachejson, 'w') as json_d:
		json.dump(cacheobj, json_d)
		json_d.close()

#####################
# lockfile operations

def get_lockfile():
	pass

def release_lockfile():
	pass

#####################

main()
