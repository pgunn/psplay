#!/usr/bin/python

import argparse
import json
import lockfile
import os
import re
import subprocess
import sys
import time

###########
# psplay_client is the "client" component of psplay - it runs frequently from
# cron, and iterates over all registered splaykeys for this system. Registered
# by config management.
#
# Operational model:
#	A splaykey (skey) is used to define host-specific splay for 1+
#		services that use that splaykey
#	psplay_client schedules "atservices" at defined times using the
#		appropriate splaykey and the atservice definition as a factor
#		for when things run
#	Splaykeys come from outside the system, and psplay_client responds
#		to those by adjusting when things run, in a way that's kind to
#		the reasons people splay in the first place
#
# For each such splaykey:
#	Read the old attribute from the local cache (if present!)
#	Read the new attribute from mdb (if present!)
#	Update the local cache
#	Reason about moratoriums statefully
#	Determine from those when it should next be scheduled
#	Determine if it already is so scheduled
#	If it is:
#		Everything is great
#	Otherwise:
#		Cancel any existing scheules of it
#		Schedule it correctly
#
# Data it works with:
#	machine tagging database - reads
#	moratorium file
#	old attribute cache
#	at - reads, schedules, cancels
#
# Improvements possible:
#	* The handling of cachefiles can be made more efficient

def main():
	cfg = handle_args()
	morat = load_moratoria(cfg.morfile) # RO-cache
	expire_old_moratoriums(morat, cfg.morfile)
	mylock = get_lockfile(cfg.lockfile)
	for skey in get_skey_list(cfg.sdefdir):
		sdef = load_sdef(skey, cfg.sdefdir) # RO-cache
		# Process this host's skeys
		oldval = get_offset_for_skey_cache(skey, cfg.cachefile)
		newval = get_offset_for_skey_mtag(skey)
		if oldval != newval: # Be careful comparing fractions!
			cache_setval(skey, newval, cfg.cachefile)
			deschedule_atservices_with_skey(skey)
			if newval < oldval:
				set_moratorium(skey, newval, morat, cfg.morfile)
		if (! in_moratorium(skey, morat)):
			for service in services_linked_to_key(skey):
				if !atservice_scheduled(skey, service):
					schedule_atservice(skey, sdef, service)
	release_lockfile(mylock)

def handle_args():
	# cfg.cachefile
	# cfg.morfile - moratorium file (no user servicable parts)
	# cfg.sdefdir - service definition dir
	pass


###################
# service definition operations
#
# Long-term storage is a directory of config files, one per skey
# Each config file defines a hash of hashes:
#	atservice_name =>
#		'cmd' => command
#		'offset' => offset (seconds)
#		'freq' => frequency_definition (in seconds)
#
# load_sdef() will load one of these and, parsing each one and returning
# a data structure that matches that. These functions are READONLY; they
# only consume service definitions; defs are written by some external
# process (such as a config management tool). 
#
# A lot of therse are accessors, but it's easier to change how a function
# works than rework stuff that looks like base language plumbing

def get_skey_list(dir):
	""" Return all defined service keys """
	maybe = os.listdir(dir)
	ret = []
	for mayb in maybe: # Ignore non-json files
		if '.json' in mayb:
			ret.extend(re.sub(r'\.json$', '', mayb))
	return ret

def load_sdef(skey, cfgdir):
	with open(cfgdir + '/' + skey + '.json') as jfile:
		sdef = json.load(jfile)
	return sfef

def services_linked_to_key(sdef):
	return sdef.keys()

def get_atservice_offset(sdef, atsvc):
	return sdef[atsvc]['offset']

####
# And the scheduling-specific parts of that
#
# Operationally:
# We can use "atq" to get a list of jobids, and
# "at -c jobid"
# to read the contents of a job. The latter is very noisy.
# "atrm" can remove a job.
#
# It'd be tempting to use job queues so we can efficiently delete
# lots of jobs at once, but there are only 26 of those and they also have
# semantic significance that I don't want to think about.
#
# The interface that "at" gives is pretty awful in that we need
# parsing of a job to find the actual command, but we can stash the service
# key in the environment, which is kinda handy!

def deschedule_atservices_with_skey(skey):
	pass

def schedule_atservice(skey, service, servicename):
	# echo job | at -M time -f /dev/fd/0
	os.environ["SKEY"] = skey # Preserves it in the "at" job!
	os.environ["ATSVC"] = servicename
	stime = real_schedule_time(skey, service)
	runcmd(["/bin/bash", "-c", "echo \"" + service['cmd'] + "\" | at " + stime + " -f /dev/fd/0"])
	# TODO: Figure out a better way to do the above
	del os.environ["SKEY"]
	del os.environ["ATSVC"]
	pass

def atservice_scheduled(skey, service):
	pass

def real_schedule_time(skey, atservice):
	""" Returns the actual time a service should next run """
	# This is based on:
	#	The skey+machine specific offset, which is a 0-1 fraction
	#	The atservice-specific offset, which is seconds
	#	The skey specific frequency
	#	The current time

####
# Internal "at" functions



###################
# moratorium operations
#
# Long-term storage is in a json file, but we'll load/parse a RO copy
# when the program starts up. The file is a simple hash:
#	skey => epochtime
# epochtime being when the moratorium expires

def load_moratoria(mfile):
	with open(mfile, 'r') as mfh:
		ret = json.load(mfh)
	return ret

def expire_old_moratoriums(mcache, mdir):
	changed = False
	for skey in mcache.keys():
		if mcache[skey] > int(time.time())
			del mcache[skey]
			changed = True
	if changed:
		with open(mfile, 'w') as mfh:
			json.dump(mcache, mfh)

def set_moratorium(skey, newval, mcache, mfile):
	mcache[skey] = newval
	with open(mfile, 'w') as mfh:
		json.dump(mcache, mfh)

def in_moratorium(skey, mcache):
	# We've already expired old moratoria, so if there's an entry, we're
	# in one. XXX Revise if this is ever run as part of a long-running process,
	# but if that happens we also need to change the expiry logic
	if skey in mcache.keys():
		return True
	return False


###################
# low-level at operations

###################
# local mtag cache operations
#
# This manipulates a hash on disk that stores old mtag values so we can spot
# config changes upstream and react to them when they happen. This initial
# implementation is inefficient.

def get_offset_for_skey_cache(skey, cachefile):
	with open(cachefile, 'r') as cfh:
		cache = json.load(cfh)
	return cache[skey]	# I think if it wasn't defined before, 
				# the compare will still work out right

def cache_setval(skey, newval, cachefile):
	with open(cachefile, 'r') as cfh:
		cache = json.load(cfh)
	cache[skey] = newval
	with open(cachefile, 'w') as cfh:
		cache = json.dump(cache, cfh)


###################
# mtag operations

def get_offset_for_skey_mtag(skey):
	""" RO """
	(ret, offset) = runcmd_with_output(['./get_hosts_for_skey_mtag', skey])

###################
# lockfile operations

def get_lockfile(lf):
	# See psplay_server
	lock = LockFile(lf)
	lock.acquire(timeout=30) # seconds
	return lock

def release_lockfile(lock):
	lock.release()

###################
# runcmd                                                                        
                                                                                
def runcmd_with_output(cmd_listform):                                           
        retstr = ""                                                             
        try:                                                                    
                retstr = subprocess.check_output(cmd_listform)                  
                retval = 0                                                      
        except:                                                                 
                retval = 1                                                      
        return retval, retstr                                                   

def runcmd(cmd_listform):
	return subprocess.call(cmd_listform)

main() 


main()
