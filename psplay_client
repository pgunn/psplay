#!/usr/bin/python

import argparse
import json
import lockfile
import os
import re
import subprocess
import sys
import time

###########
# psplay_client is the "client" component of psplay - it runs frequently from
# cron, and iterates over all registered splaykeys for this system. Registered
# by config management.
#
# Operational model:
#	A splaykey (skey) is used to define host-specific splay for 1+
#		services that use that splaykey
#	psplay_client schedules "atservices" at defined times using the
#		appropriate splaykey and the atservice definition as a factor
#		for when things run
#	Splaykeys come from outside the system, and psplay_client responds
#		to those by adjusting when things run, in a way that's kind to
#		the reasons people splay in the first place
#
# For each such splaykey:
#	Read the old attribute from the local cache (if present!)
#	Read the new attribute from mdb (if present!)
#	Update the local cache
#	Reason about moratoriums statefully
#	Determine from those when it should next be scheduled
#	Determine if it already is so scheduled
#	If it is:
#		Everything is great
#	Otherwise:
#		Cancel any existing scheules of it
#		Schedule it correctly
#
# Data it works with:
#	machine tagging database - reads
#	moratorium file
#	old attribute cache
#	at - reads, schedules, cancels
#
# Improvements possible:
#	* The handling of cachefiles can be made more efficient

def main():
	cfg = handle_args()
	morat = load_moratoria(cfg.morfile) # RO-cache
	expire_old_moratoriums(morat, cfg.morfile)
	mylock = get_lockfile(cfg.lockfile)
	for skey in get_skey_list(cfg.sdefdir):
		sdef = load_sdef(skey, cfg.sdefdir) # RO-cache
		# Process this host's skeys
		oldval = get_offset_for_skey_cache(skey, cfg.cachefile)
		newval = get_offset_for_skey_mtag(skey, cfg.gofsmcmd)
		if oldval != newval: # Be careful comparing fractions!
			cache_setval(skey, newval, cfg.cachefile)
			deschedule_atservices_with_skey(skey)
			if newval < oldval:
				set_moratorium(skey, oldval, morat, cfg.morfile)
		if (! in_moratorium(skey, morat)):
			for service in services_linked_to_key(skey):
				if !atservice_scheduled(skey, service):
					schedule_atservice(skey, sdef, service, newval)
	release_lockfile(mylock)

def handle_args():
	# cfg.cachefile
	# cfg.morfile - moratorium file (no user servicable parts)
	# cfg.sdefdir - service definition dir
	optmsgs = {
		"cachefile" : "Cache of upstream offsets",
		"morfile" : "Moratorium storage",
		"sdefdir" : "Service Definitions",
		"gofsmcmd": "Command that, given a skey, returns its offset on this machine"
	}
	parser = argparse.ArgumentParser()
	parser.add_argument('--cachefile', help=optmsgs['cachefile'],
		default='/var/run/psplay_c-cachefile.json')
	parser.add_argument('--morfile', help=optmsgs['morfile'],
		default='/var/run/psplay_c-morfile.json')
	parser.add_argument('--sdefdir', help=optmsgs['sdefdir'],
		default='/var/run/psplay_c-sdefs')
	parser.add_argument('--gofsmcmd', help=optmsgs['gofsmcmd'],
		required=True)
	return parser.parse_args()


###################
# service definition operations
#
# Long-term storage is a directory of config files, one per skey
# Each config file defines a hash of hashes:
#	atservice_name =>
#		'cmd' => command
#		'offset' => offset (seconds)
#		'freq' => frequency_definition (in seconds)
#
# load_sdef() will load one of these and, parsing each one and returning
# a data structure that matches that. These functions are READONLY; they
# only consume service definitions; defs are written by some external
# process (such as a config management tool). 
#
# A lot of therse are accessors, but it's easier to change how a function
# works than rework stuff that looks like base language plumbing

def get_skey_list(dir):
	""" Return all defined service keys """
	maybe = os.listdir(dir)
	ret = []
	for mayb in maybe: # Ignore non-json files
		if '.json' in mayb:
			ret.extend(re.sub(r'\.json$', '', mayb))
	return ret

def load_sdef(skey, cfgdir):
	with open(cfgdir + '/' + skey + '.json') as jfile:
		sdef = json.load(jfile)
	return sfef

def services_linked_to_key(sdef):
	return sdef.keys()

####
# And the scheduling-specific parts of that
#
# Operationally:
# We can use "atq" to get a list of jobids, and
# "at -c jobid"
# to read the contents of a job. The latter is very noisy.
# "atrm" can remove a job.
#
# It'd be tempting to use job queues so we can efficiently delete
# lots of jobs at once, but there are only 26 of those and they also have
# semantic significance that I don't want to think about.
#
# The interface that "at" gives is pretty awful in that we need
# parsing of a job to find the actual command, but we can stash the service
# key in the environment, which is kinda handy!

def deschedule_atservices_with_skey(skey):
	atdata = at_status()
	if skey in atdata.keys():
		for atjob in atdata[skey]:
			runcmd(['atrm', str(atjob['jid'])])	# Should already be a string,
								# but let's be defensive

def schedule_atservice(skey, service, servicename, mtagtime):
	# echo job | at -M time -f /dev/fd/0
	os.environ["SKEY"] = skey # Preserves it in the "at" job!
	os.environ["ATSVC"] = servicename
	zeit = real_schedule_time(skey, service, mtagtime)
	stime = time.strftime('%H:%M %B %d %Y', zeit) # "at" cannot handle seconds!
	runcmd(["/bin/bash", "-c", "echo \"" + service['cmd'] + "\" | at " + stime + " -f /dev/fd/0"])
	# TODO: Figure out a better way to do the above
	del os.environ["SKEY"]
	del os.environ["ATSVC"]

def atservice_scheduled(skey, atservice):
	atdata = at_status()
	if ! skey in atdata.keys():
		return False
	for atjob in atdata[skey]:
		if atjob['atsvc'] == atservice:
			return True
	return False

def real_schedule_time(skey, sdef, mtagtime):
	""" Returns the actual epochtime a service should next run """
	# This is based on:
	#	The skey+machine specific offset, which is a 0-1 fraction (arg)
	#	The atservice-specific offset, which is seconds
	#	The skey specific frequency
	#	The current time
	skey_freq = sdef['freq']
	dynamic_offset_seconds = mtagtime * skey_freq
	static_offset_seconds = sdef['offset']
	base = epoch_beginning_today()
	candidate_time = base + static_offset_seconds + static_offset_seconds
	while candidate_time < now():
		candidate_time += skey_freq
	return candidate_time
####
# Internal "at" functions

def get_all_atjobs():
	""" Returns all jobs that at can see, as a string list"""
	(cmdret, res) = runcmd_with_output(["atq"])
	ret = []
	for line in res:
		(atidx, _) = string.split(line, maxsplit=1)
		ret.extend(atidx)
	return ret

def describe_atjob(atjid):
	""" Pass in the numeric id at uses to refer to a job.
	Returns a list: (skey, atsvc, cmdline), first two of which might
	not be set """
	(cmdret, res) = runcmd_with_output(["at", "-c", atjid])
	magicline = ""
	for line in res:
		if line.startswith("SKEY="):
			# Syntax for these lines is:
			# SKEY=FOO; export SKEY
			# So if we split by ; and then = we have the value
			(firstpart, _) = string.split(line, sep=';', maxsplit=1)
			(_, val) = string.split(firstpart, sep='=', maxsplit=1)
			skey = val
		elif line.startswith("ATSVC="):
			(firstpart, _) = string.split(line, sep=';', maxsplit=1)
			(_, val) = string.split(firstpart, sep='=', maxsplit=1)
			atsvc = val
		if line.rstrip() != "":
			magicline = line
	# Post-loop:
	# 	magicline holds the last nonblank line
	#	we've had time to extract the saved values of skey and atsvc
	return skey, atsvc, magicline

def at_status():
	""" Returns a data structure summarising what is in at
	Note that this is very dependent on the syntax of the at
	command on the system.

	Structure is (presently a hash):
		skey => [{'jid' => atjid, 'atsvc' => atsvc }, ... ]
	We don't currently stash the "atsvc" value into this, even though
	we put it into at for later retrieval. If we develop a use for it,
	we'll extract and expose it """
	atjids = get_all_atjobs()
	ret = {}
	for atjid in atjids:
		(skey, atsvc, magicline) = describe_atjob(atjid)
		if skey is None: # Not one of ours
			continue
		if atsvc is None: # How did this happen.
			continue
		if not skey in ret.keys():
			ret[skey] = []
		atjdata = {}
		atjdata['jid'] = atjid
		atjdata['atsvc'] = atsvc
		ret[skey].extend(atjdata)
	return ret


###################
# moratorium operations
#
# Long-term storage is in a json file, but we'll load/parse a RO copy
# when the program starts up. The file is a simple hash:
#	skey => epochtime
# epochtime being when the moratorium expires

def load_moratoria(mfile):
	with open(mfile, 'r') as mfh:
		ret = json.load(mfh)
	return ret

def expire_old_moratoriums(mcache, mdir):
	changed = False
	for skey in mcache.keys():
		if mcache[skey] > int(time.time())
			del mcache[skey]
			changed = True
	if changed:
		with open(mfile, 'w') as mfh:
			json.dump(mcache, mfh)

def set_moratorium(skey, val, mcache, mfile):
	mcache[skey] = val
	with open(mfile, 'w') as mfh:
		json.dump(mcache, mfh)

def in_moratorium(skey, mcache):
	# We've already expired old moratoria, so if there's an entry, we're
	# in one. XXX Revise if this is ever run as part of a long-running process,
	# but if that happens we also need to change the expiry logic
	if skey in mcache.keys():
		return True
	return False


###################
# low-level at operations

###################
# local mtag cache operations
#
# This manipulates a hash on disk that stores old mtag values so we can spot
# config changes upstream and react to them when they happen. This initial
# implementation is inefficient.

def get_offset_for_skey_cache(skey, cachefile):
	with open(cachefile, 'r') as cfh:
		cache = json.load(cfh)
	return cache[skey]	# I think if it wasn't defined before, 
				# the compare will still work out right

def cache_setval(skey, newval, cachefile):
	with open(cachefile, 'r') as cfh:
		cache = json.load(cfh)
	cache[skey] = newval
	with open(cachefile, 'w') as cfh:
		cache = json.dump(cache, cfh)


###################
# mtag operations

def get_offset_for_skey_mtag(skey, cmd):
	""" RO """
	(ret, out) = runcmd_with_output([cmd, skey])
	ret = []
	for line in out:
		ret.extend(line.rstrip())
	return ret

###################
# lockfile operations

def get_lockfile(lf):
	# See psplay_server
	lock = LockFile(lf)
	lock.acquire(timeout=30) # seconds
	return lock

def release_lockfile(lock):
	lock.release()

###################
# runcmd                                                                        
                                                                                
def runcmd_with_output(cmd_listform):                                           
        retstr = ""                                                             
        try:                                                                    
                retstr = subprocess.check_output(cmd_listform)                  
                retval = 0                                                      
        except:                                                                 
                retval = 1                                                      
        return retval, retstr                                                   

def runcmd(cmd_listform):
	return subprocess.call(cmd_listform)

main()
